import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import numpy as np
import smtplib
from email.message import EmailMessage

# üì¶ Charger les identifiants de l'email depuis st.secrets
EMAIL_ADDRESS = st.secrets["EMAIL_USER"]
EMAIL_PASSWORD = st.secrets["EMAIL_PASS"]

# üì• Charger FinBERT
@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained("yiyanghkust/finbert-tone")
    model = AutoModelForSequenceClassification.from_pretrained("yiyanghkust/finbert-tone")
    return tokenizer, model

tokenizer, model = load_model()

# ‚úâÔ∏è Fonction d'envoi d'email
def send_email(subject, body, to="pauljean.pecoraro@gmail.com"):
    msg = EmailMessage()
    msg.set_content(body)
    msg['Subject'] = subject
    msg['From'] = EMAIL_ADDRESS
    msg['To'] = to

    try:
        with smtplib.SMTP_SSL('smtp.gmail.com', 465) as smtp:
            smtp.login(EMAIL_ADDRESS, EMAIL_PASSWORD)
            smtp.send_message(msg)
    except Exception as e:
        st.error(f"Erreur lors de l'envoi de l'email : {e}")

# üéõÔ∏è Interface Streamlit
st.title("Test d'Explicabilit√© du Mod√®le FinBERT")

# üìù Texte d'entr√©e
user_input = st.text_area("Entrez un extrait d'actualit√© financi√®re, un tweet ou un commentaire d'analyste :")

# üìä Ex√©cution de FinBERT
if user_input:
    inputs = tokenizer(user_input, return_tensors="pt", truncation=True)
    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
        probs_np = probs[0].numpy()
        labels = ['N√©gatif', 'Neutre', 'Positif']

    st.subheader("Classification du Sentiment par FinBERT")
    for label, prob in zip(labels, probs_np):
        st.write(f"**{label}** : {prob:.2%}")

    # üß† Questionnaire
    st.subheader("Questionnaire sur l'Explicabilit√©")
    clarity = st.radio("Dans quelle mesure la classification du sentiment vous semble-t-elle claire ?", ["Tr√®s peu claire", "Plut√¥t peu claire", "Neutre", "Plut√¥t claire", "Tr√®s claire"])
    explainability = st.radio("Pourriez-vous expliquer ce r√©sultat √† un client ou un auditeur ?", ["Certainement pas", "Probablement pas", "Je ne sais pas", "Probablement oui", "Certainement oui"])
    usefulness = st.radio("Ce r√©sultat vous aide-t-il √† prendre une d√©cision d'investissement ?", ["Pas du tout", "Un peu", "Moyennement", "Beaucoup", "√ânorm√©ment"])

    # üîÑ Simulation inverse
    st.subheader("Simulation Inverse")
    user_guess = st.radio("Quel sentiment pensez-vous que le mod√®le a identifi√© ?", labels)

    # ‚úçÔ∏è R√©√©criture
    st.subheader("D√©fi de R√©√©criture")
    rewrite_input = st.text_area("Essayez de r√©√©crire la phrase pour changer le sentiment :")

    if rewrite_input.strip():
        rewrite_inputs = tokenizer(rewrite_input, return_tensors="pt", truncation=True)
        with torch.no_grad():
            rewrite_outputs = model(**rewrite_inputs)
            rewrite_probs = torch.nn.functional.softmax(rewrite_outputs.logits, dim=-1)
            rewrite_probs_np = rewrite_probs[0].numpy()

        st.markdown("**Analyse de Sentiment du Texte R√©√©crit :**")
        for label, prob in zip(labels, rewrite_probs_np):
            st.write(f"**{label}** : {prob:.2%}")

    # üì¨ Envoi des r√©ponses
    if st.button("Soumettre le Questionnaire"):
        body = f"""
        Texte original : {user_input}
        Pr√©diction FinBERT :
        - N√©gatif : {probs_np[0]:.2%}
        - Neutre : {probs_np[1]:.2%}
        - Positif : {probs_np[2]:.2%}

        Sentiment pr√©dit par l'utilisateur : {user_guess}
        Texte r√©√©crit : {rewrite_input}

        R√©ponses au questionnaire :
        - Clart√© : {clarity}
        - Explicabilit√© : {explainability}
        - Utilit√© : {usefulness}
        """
        send_email("Nouvelle r√©ponse au questionnaire FinBERT", body)
        st.success("Votre r√©ponse a bien √©t√© envoy√©e au chercheur ! ‚úÖ")
